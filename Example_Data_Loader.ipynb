{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## DataLoader in SpeechBrain"
      ],
      "metadata": {
        "id": "d0fAFAp8H2_O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. SpeechBrain Data Loading Pipeline follows Pytorch Data Loading Pipeline.\n",
        "2. The Pytorch Data Loading Pipeline consists of the following argument :\n",
        "  * **Dataset** : It loads one data point at a time\n",
        "  * **Collation Function** : This converts the dataset into Pytorch Tensor batches\n",
        "  * **Sampler** : decides how the dataset should be iterated\n",
        "  * **Data Loader** : This takes the above mentioned and other arguments like batch_size and creates instances of data which are iterated during training\n",
        "  This link contains\n",
        "\n",
        "3. You can also **directly load the data** to the brain.fit ( ) function and specify the data loader options (such as batch size) in train_loader_kwargs argument taken from the yaml file. \n",
        "\n",
        ">For example :\n",
        "brain.fit(range(hparams[\"N_epochs\"]), data, train_loader_kwargs=hparams[\"dataloader_options\"])"
      ],
      "metadata": {
        "id": "IRB7HLT5HKPG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hqHP8NwyF6xi"
      },
      "outputs": [],
      "source": [
        "pip install speechbrain"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import speechbrain as sb"
      ],
      "metadata": {
        "id": "dpXDuW1GI7hs"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleBrain(sb.Brain):\n",
        "\n",
        "  # This method  take the batch and computes the forward pass\n",
        "  \n",
        "  def compute_forward(self, batch, stage):\n",
        "    #print(batch[0])\n",
        "    return self.modules.model(batch[0])\n",
        "\n",
        "  # This method takes the  predictions and labels to minimize the \n",
        "  #loss function and updates the weights\n",
        "\n",
        "  def compute_objectives(self, predictions, batch, stage):\n",
        "    return torch.nn.functional.l1_loss(predictions, batch[1])\n"
      ],
      "metadata": {
        "id": "wB7D443AJAX0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data with random tensor just for demonstration\n",
        "data=[]\n",
        "for i in range(10):\n",
        "  data.append([torch.rand(10, 10), torch.rand(10, 10)])\n",
        "\n"
      ],
      "metadata": {
        "id": "yvy7h70WXnuC"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_new = torch.utils.data.DataLoader(data,batch_size=4, shuffle=False)"
      ],
      "metadata": {
        "id": "1boQWJbXcxAh"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define a torch model consisiting of single linear layer\n",
        "model = torch.nn.Linear(in_features=10, out_features=10)\n",
        "\n",
        "#Brain class is defined by taking the model,optimiser class\n",
        "brain = SimpleBrain({\"model\": model}, opt_class=lambda x: torch.optim.SGD(x, 0.1),)\n",
        "\n",
        "#Use the fit method to train the model \n",
        "#brain.fit(range(10), data)\n",
        "brain.fit(range(10),  data_new)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXYO-ZxhJB97",
        "outputId": "14497426-2aac-4c34-f7e6-bb06f41f112a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00, 135.48it/s, train_loss=0.607]\n",
            "100%|██████████| 3/3 [00:00<00:00, 141.62it/s, train_loss=0.537]\n",
            "100%|██████████| 3/3 [00:00<00:00, 194.83it/s, train_loss=0.475]\n",
            "100%|██████████| 3/3 [00:00<00:00, 171.56it/s, train_loss=0.423]\n",
            "100%|██████████| 3/3 [00:00<00:00, 164.90it/s, train_loss=0.381]\n",
            "100%|██████████| 3/3 [00:00<00:00, 166.45it/s, train_loss=0.35]\n",
            "100%|██████████| 3/3 [00:00<00:00, 188.20it/s, train_loss=0.327]\n",
            "100%|██████████| 3/3 [00:00<00:00, 185.42it/s, train_loss=0.311]\n",
            "100%|██████████| 3/3 [00:00<00:00, 207.32it/s, train_loss=0.299]\n",
            "100%|██████████| 3/3 [00:00<00:00, 185.44it/s, train_loss=0.291]\n"
          ]
        }
      ]
    }
  ]
}